{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wissal9999999999999/-Graph-Based-Enrichment-Ontology-Approach/blob/main/CNNs_TL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "try:\n",
        "    import numpy as np\n",
        "    import torch\n",
        "    import torchvision\n",
        "    assert int(torch.__version__.split(\".\")[1]) >= 12, \"torch version should be 1.12+\"\n",
        "    assert int(torchvision.__version__.split(\".\")[1]) >= 13, \"torchvision version should be 0.13+\"\n",
        "    print(f\"torch version: {torch.__version__}\")\n",
        "    print(f\"torchvision version: {torchvision.__version__}\")\n",
        "except:\n",
        "    print(f\"[INFO] torch/torchvision versions not as required, installing nightly versions.\")\n",
        "    os.system(\"pip install -U torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113\")\n",
        "    import torch\n",
        "    import torchvision\n",
        "    print(f\"torch version: {torch.__version__}\")\n",
        "    print(f\"torchvision version: {torchvision.__version__}\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "\n",
        "try:\n",
        "    from torchinfo import summary\n",
        "except:\n",
        "    print(\"[INFO] Couldn't find torchinfo... installing it.\")\n",
        "    os.system(\"pip install -q torchinfo\")\n",
        "    from torchinfo import summary\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "import os\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "from typing import Dict, List, Tuple\n",
        "NUM_WORKERS = os.cpu_count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6G9x36oOeEf",
        "outputId": "5fcbb62d-b710-4574-d8c9-7c2d4639f7e3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] torch/torchvision versions not as required, installing nightly versions.\n",
            "torch version: 2.3.0+cu121\n",
            "torchvision version: 0.18.0+cu121\n",
            "[INFO] Couldn't find torchinfo... installing it.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def install_package(package):\n",
        "    try:\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\"] + package.split())\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"[ERROR] Failed to install {package}. Error: {e}\")\n",
        "        sys.exit(1)\n",
        "\n",
        "try:\n",
        "    import numpy as np\n",
        "    import torch\n",
        "    import torchvision\n",
        "    assert int(torch.__version__.split(\".\")[1]) >= 12, \"torch version should be 1.12+\"\n",
        "    assert int(torchvision.__version__.split(\".\")[1]) >= 13, \"torchvision version should be 0.13+\"\n",
        "    print(f\"torch version: {torch.__version__}\")\n",
        "    print(f\"torchvision version: {torchvision.__version__}\")\n",
        "except (AssertionError, ImportError) as e:\n",
        "    print(f\"[INFO] torch/torchvision versions not as required, installing nightly versions.\")\n",
        "    print(f\"[INFO] Reason: {e}\")\n",
        "    install_package(\"torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113\")\n",
        "    import torch\n",
        "    import torchvision\n",
        "    print(f\"torch version: {torch.__version__}\")\n",
        "    print(f\"torchvision version: {torchvision.__version__}\")\n",
        "\n",
        "try:\n",
        "    from torchinfo import summary\n",
        "except ImportError:\n",
        "    print(\"[INFO] Couldn't find torchinfo... installing it.\")\n",
        "    install_package(\"torchinfo\")\n",
        "    from torchinfo import summary\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import nn\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm.auto import tqdm\n",
        "from typing import Dict, List, Tuple\n",
        "from pathlib import Path\n",
        "\n",
        "# Constants\n",
        "NUM_WORKERS = os.cpu_count()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQ0Wiqd6APq0",
        "outputId": "6e782769-4f2f-4b2e-e810-8677a0b215e3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] torch/torchvision versions not as required, installing nightly versions.\n",
            "[INFO] Reason: torch version should be 1.12+\n",
            "torch version: 2.3.0+cu121\n",
            "torchvision version: 0.18.0+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FCs3Kp7lAPrv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "HXa0_H2aOhC9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training and testing block\n",
        "\n",
        "def train_step(model: torch.nn.Module,\n",
        "               dataloader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               optimizer: torch.optim.Optimizer,\n",
        "               device: torch.device) -> Tuple[float, float]:\n",
        "\n",
        "    # Put model in train mode\n",
        "    model.train()\n",
        "\n",
        "    # Setup train loss and train accuracy values\n",
        "    train_loss, train_acc = 0, 0\n",
        "\n",
        "    # Loop through data loader data batches\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # Send data to target device\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # 1. Forward pass\n",
        "        y_pred = model(X)\n",
        "\n",
        "        # 2. Calculate  and accumulate loss\n",
        "        loss = loss_fn(y_pred, y)\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        # 3. Optimizer zero grad\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 4. Loss backward\n",
        "        loss.backward()\n",
        "\n",
        "        # 5. Optimizer step\n",
        "        optimizer.step()\n",
        "\n",
        "        # Calculate and accumulate accuracy metric across all batches\n",
        "        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
        "        train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n",
        "\n",
        "    # Adjust metrics to get average loss and accuracy per batch\n",
        "    train_loss = train_loss / len(dataloader)\n",
        "    train_acc = train_acc / len(dataloader)\n",
        "    return train_loss, train_acc\n",
        "\n",
        "def test_step(model: torch.nn.Module,\n",
        "              dataloader: torch.utils.data.DataLoader,\n",
        "              loss_fn: torch.nn.Module,\n",
        "              device: torch.device) -> Tuple[float, float]:\n",
        "\n",
        "    # Put model in eval mode\n",
        "    model.eval()\n",
        "\n",
        "    # Setup test loss and test accuracy values\n",
        "    test_loss, test_acc = 0, 0\n",
        "\n",
        "    # Turn on inference context manager\n",
        "    with torch.inference_mode():\n",
        "        # Loop through DataLoader batches\n",
        "        for batch, (X, y) in enumerate(dataloader):\n",
        "            # Send data to target device\n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "            # 1. Forward pass\n",
        "            test_pred_logits = model(X)\n",
        "\n",
        "            # 2. Calculate and accumulate loss\n",
        "            loss = loss_fn(test_pred_logits, y)\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            # Calculate and accumulate accuracy\n",
        "            test_pred_labels = test_pred_logits.argmax(dim=1)\n",
        "            test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
        "\n",
        "    # Adjust metrics to get average loss and accuracy per batch\n",
        "    test_loss = test_loss / len(dataloader)\n",
        "    test_acc = test_acc / len(dataloader)\n",
        "    return test_loss, test_acc\n",
        "\n",
        "def train(model: torch.nn.Module,\n",
        "          train_dataloader: torch.utils.data.DataLoader,\n",
        "          test_dataloader: torch.utils.data.DataLoader,\n",
        "          optimizer: torch.optim.Optimizer,\n",
        "          loss_fn: torch.nn.Module,\n",
        "          epochs: int,\n",
        "          device: torch.device) -> Dict[str, List]:\n",
        "\n",
        "\n",
        "    results = {\"train_loss\": [],\n",
        "               \"train_acc\": [],\n",
        "               \"test_loss\": [],\n",
        "               \"test_acc\": []\n",
        "    }\n",
        "\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        train_loss, train_acc = train_step(model=model,\n",
        "                                          dataloader=train_dataloader,\n",
        "                                          loss_fn=loss_fn,\n",
        "                                          optimizer=optimizer,\n",
        "                                          device=device)\n",
        "        test_loss, test_acc = test_step(model=model,\n",
        "          dataloader=test_dataloader,\n",
        "          loss_fn=loss_fn,\n",
        "          device=device)\n",
        "\n",
        "        # Print out what's happening\n",
        "        print(\n",
        "          f\"Epoch: {epoch+1} | \"\n",
        "          f\"train_loss: {train_loss:.4f} | \"\n",
        "          f\"train_acc: {train_acc:.4f} | \"\n",
        "          f\"test_loss: {test_loss:.4f} | \"\n",
        "          f\"test_acc: {test_acc:.4f}\"\n",
        "        )\n",
        "\n",
        "        # Update results dictionary\n",
        "        results[\"train_loss\"].append(train_loss)\n",
        "        results[\"train_acc\"].append(train_acc)\n",
        "        results[\"test_loss\"].append(test_loss)\n",
        "        results[\"test_acc\"].append(test_acc)\n",
        "\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "jSWLLENSPa8t"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Data"
      ],
      "metadata": {
        "id": "hiuYnxM6Xyny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "Qwwx9lFGGCCU",
        "outputId": "68aaeeb7-fff5-436f-a844-ffff4541f685"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-cc24596e-a556-47e6-a0b2-fb2ceccc53a4\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-cc24596e-a556-47e6-a0b2-fb2ceccc53a4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving datamodel.zip to datamodel.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extraire le contenu du fichier zip dans le dossier dataset\n",
        "!unzip -q datamodel.zip -d dataset\n"
      ],
      "metadata": {
        "id": "gemzqnBxGNY3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Chemin du dossier dataset\n",
        "dataset_path = \"/content/dataset\"\n",
        "\n",
        "# Noms des classes\n",
        "classes = os.listdir(os.path.join(dataset_path, 'train'))  # Nous choisissons arbitrairement le dossier 'train' pour obtenir la liste des classes\n",
        "print(\"Nombre de classes :\", len(classes))\n",
        "\n",
        "# Parcourir chaque classe\n",
        "for class_name in classes:\n",
        "    # Afficher le nom de la classe\n",
        "    print(f\"Classe : {class_name}\")\n",
        "\n",
        "    # Compter le nombre d'images dans chaque ensemble (train, validation, test)\n",
        "    for subset in ['train', 'validation', 'test']:\n",
        "        # Chemin du sous-dossier spécifique pour cette classe et cet ensemble\n",
        "        subset_path = os.path.join(dataset_path, subset, class_name)\n",
        "\n",
        "        # Vérifier si le dossier existe\n",
        "        if os.path.exists(subset_path):\n",
        "            # Compter le nombre d'images dans le sous-dossier\n",
        "            num_images = len(os.listdir(subset_path))\n",
        "            print(f\"  Nombre d'images dans {subset} : {num_images}\")\n",
        "        else:\n",
        "            print(f\"  Le dossier {subset} pour la classe {class_name} n'existe pas.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVnDnpSdMsMA",
        "outputId": "74bca101-91d7-4bcb-c705-0fe464a3e1f6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nombre de classes : 2\n",
            "Classe : liver_tumor\n",
            "  Nombre d'images dans train : 12629\n",
            "  Nombre d'images dans validation : 3563\n",
            "  Nombre d'images dans test : 1852\n",
            "Classe : liver_normal\n",
            "  Nombre d'images dans train : 20520\n",
            "  Nombre d'images dans validation : 5408\n",
            "  Nombre d'images dans test : 2937\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/dataset\"\n",
        "\n",
        "\n",
        "\n",
        "# Setup Dirs\n",
        "train_dir = image_path + \"/train\"\n",
        "test_dir = image_path + \"/test\"\n",
        "\n",
        "\n",
        "manual_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)), # 1. Reshape all images to 224x224 (though some models may require different sizes)\n",
        "    transforms.ToTensor(), # 2. Turn image values to between 0 & 1\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], # 3. A mean of [0.485, 0.456, 0.406] (across each colour channel)\n",
        "                         std=[0.229, 0.224, 0.225]) # 4. A standard deviation of [0.229, 0.224, 0.225] (across each colour channel),\n",
        "])\n"
      ],
      "metadata": {
        "id": "HEz7e-4QOs2N"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def create_dataloaders(\n",
        "    train_dir: str,\n",
        "    test_dir: str,\n",
        "    transform: transforms.Compose,\n",
        "    batch_size: int,\n",
        "    num_workers: int=NUM_WORKERS\n",
        "):\n",
        "\n",
        "\n",
        "  train_data = datasets.ImageFolder(train_dir, transform=transform)\n",
        "  test_data = datasets.ImageFolder(test_dir, transform=transform)\n",
        "\n",
        "\n",
        "  class_names = train_data.classes\n",
        "\n",
        "\n",
        "  train_dataloader = DataLoader(\n",
        "      train_data,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=True,\n",
        "      num_workers=num_workers,\n",
        "      pin_memory=True,\n",
        "  )\n",
        "  test_dataloader = DataLoader(\n",
        "      test_data,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=False,\n",
        "      num_workers=num_workers,\n",
        "      pin_memory=True,\n",
        "  )\n",
        "\n",
        "  return train_dataloader, test_dataloader, class_names\n",
        "\n",
        "\n",
        "train_dataloader, test_dataloader, class_names = create_dataloaders(train_dir=train_dir,\n",
        "                                                                               test_dir=test_dir,\n",
        "                                                                               transform=manual_transforms, # resize, convert images to between 0 & 1 and normalize them\n",
        "                                                                               batch_size=32) # set mini-batch size to 32\n"
      ],
      "metadata": {
        "id": "2Xn8vhPBO1Sl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For resnet18"
      ],
      "metadata": {
        "id": "iZRHxrg6QBH2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Configurer l'appareil\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "3lDG_90EPf0g"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights = torchvision.models.ResNet18_Weights.DEFAULT\n",
        "model = torchvision.models.resnet18(pretrained=True).to(device)\n",
        "\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# train all params\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "output_shape = len(class_names)\n",
        "\n",
        "\n",
        "model.classifier = torch.nn.Sequential(\n",
        "    torch.nn.Dropout(p=0.2, inplace=True),\n",
        "    torch.nn.Linear(in_features=512,\n",
        "                    out_features=output_shape,\n",
        "                    bias=True)).to(device)\n",
        "\n",
        "\n",
        "results = train(model=model,\n",
        "                       train_dataloader=train_dataloader,\n",
        "                       test_dataloader=test_dataloader,\n",
        "                       optimizer=optimizer,\n",
        "                       loss_fn=loss_fn,\n",
        "                       epochs=10,\n",
        "                       device=device) # best result for resnet18 was 91.25%"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLncxcgiYt8y",
        "outputId": "94f612c5-9cdc-4f72-b534-6523750b9c0f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 193MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Train Loss: 0.2652, Train Accuracy: 90.19%, Test Loss: 0.5170, Test Accuracy: 82.15%\n",
            "Epoch 2/10, Train Loss: 0.1101, Train Accuracy: 95.91%, Test Loss: 0.2006, Test Accuracy: 92.88%\n",
            "Epoch 3/10, Train Loss: 0.0838, Train Accuracy: 97.03%, Test Loss: 0.5514, Test Accuracy: 83.69%\n",
            "Epoch 4/10, Train Loss: 0.0563, Train Accuracy: 98.02%, Test Loss: 0.1722, Test Accuracy: 94.32%\n",
            "Epoch 5/10, Train Loss: 0.0490, Train Accuracy: 98.33%, Test Loss: 0.3892, Test Accuracy: 90.08%\n",
            "Epoch 6/10, Train Loss: 0.0375, Train Accuracy: 98.74%, Test Loss: 0.2784, Test Accuracy: 89.58%\n",
            "Epoch 7/10, Train Loss: 0.0329, Train Accuracy: 98.92%, Test Loss: 0.2465, Test Accuracy: 92.15%\n",
            "Epoch 8/10, Train Loss: 0.0278, Train Accuracy: 99.09%, Test Loss: 0.2681, Test Accuracy: 92.90%\n",
            "Epoch 9/10, Train Loss: 0.0245, Train Accuracy: 99.27%, Test Loss: 0.2921, Test Accuracy: 93.67%\n",
            "Epoch 10/10, Train Loss: 0.0220, Train Accuracy: 99.28%, Test Loss: 0.1927, Test Accuracy: 95.07%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_coefficient(preds, labels, smooth=1e-6):\n",
        "    \"\"\"\n",
        "    Compute the Dice coefficient.\n",
        "\n",
        "    Args:\n",
        "    preds (torch.Tensor): Predictions from the model (logits).\n",
        "    labels (torch.Tensor): Ground truth labels.\n",
        "\n",
        "    Returns:\n",
        "    float: Dice coefficient score.\n",
        "    \"\"\"\n",
        "    # Apply softmax to predictions if necessary and get predicted classes\n",
        "    preds = torch.argmax(torch.softmax(preds, dim=1), dim=1)\n",
        "\n",
        "    # Flatten tensors\n",
        "    preds = preds.contiguous().view(-1)\n",
        "    labels = labels.contiguous().view(-1)\n",
        "\n",
        "    # Compute the intersection\n",
        "    intersection = (preds * labels).sum().float()\n",
        "    # Compute the union\n",
        "    union = preds.sum().float() + labels.sum().float()\n",
        "\n",
        "    dice = (2. * intersection + smooth) / (union + smooth)\n",
        "    return dice.item()\n"
      ],
      "metadata": {
        "id": "WAL_F4huJRt8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_dataloader, test_dataloader, optimizer, loss_fn, epochs, device):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        train_correct = 0\n",
        "        train_total = 0\n",
        "        train_dice = 0  # Initialize train dice score\n",
        "\n",
        "        for batch in train_dataloader:\n",
        "            inputs, labels = batch\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "            # Précision pour l'ensemble d'entraînement\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "\n",
        "            # Dice coefficient for training\n",
        "            train_dice += dice_coefficient(outputs, labels)\n",
        "\n",
        "        train_loss /= len(train_dataloader)\n",
        "        train_accuracy = 100 * train_correct / train_total\n",
        "\n",
        "\n",
        "        model.eval()\n",
        "        test_loss = 0\n",
        "        test_correct = 0\n",
        "        test_total = 0\n",
        "        test_dice = 0  # Initialize test dice score\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in test_dataloader:\n",
        "                inputs, labels = batch\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = loss_fn(outputs, labels)\n",
        "                test_loss += loss.item()\n",
        "\n",
        "                # Précision pour l'ensemble de test\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                test_total += labels.size(0)\n",
        "                test_correct += (predicted == labels).sum().item()\n",
        "\n",
        "\n",
        "\n",
        "        test_loss /= len(test_dataloader)\n",
        "        test_accuracy = 100 * test_correct / test_total\n",
        "        test_dice /= len(test_dataloader)  # Average dice score\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "id": "9xVXT1NnJTn2"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = train(model=model,\n",
        "                train_dataloader=train_dataloader,\n",
        "                test_dataloader=test_dataloader,\n",
        "                optimizer=optimizer,\n",
        "                loss_fn=loss_fn,\n",
        "                epochs=10,\n",
        "                device=device)\n",
        "\n",
        "print(results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "cEjLQ2-EJVWG",
        "outputId": "fa9e38f4-8396-4b79-b5d4-c80938d96362"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-1d8113bebf18>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m results = train(model=model,\n\u001b[0m\u001b[1;32m      2\u001b[0m                 \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                 \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0mloss_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "\n",
        "# Définir l'appareil\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Charger les poids et le modèle\n",
        "weights = torchvision.models.ResNet18_Weights.DEFAULT\n",
        "model = torchvision.models.resnet18(weights=weights).to(device)\n",
        "\n",
        "# Définir la fonction de perte et l'optimiseur\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Permettre l'entraînement de tous les paramètres du modèle\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# Fixer les graines pour la reproductibilité\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "# Obtenir la forme de sortie (nombre de classes)\n",
        "output_shape = len(class_names)\n",
        "\n",
        "# Modifier la couche de classification du modèle\n",
        "model.fc = torch.nn.Sequential(\n",
        "    torch.nn.Dropout(p=0.2, inplace=True),\n",
        "    torch.nn.Linear(in_features=model.fc.in_features,\n",
        "                    out_features=output_shape,\n",
        "                    bias=True)).to(device)\n",
        "\n",
        "# Assurez-vous que la fonction train est définie\n",
        "def train(model, train_dataloader, test_dataloader, optimizer, loss_fn, epochs, device):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        train_correct = 0\n",
        "        train_total = 0\n",
        "\n",
        "        for batch in train_dataloader:\n",
        "            inputs, labels = batch\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "            # Précision pour l'ensemble d'entraînement\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        train_loss /= len(train_dataloader)\n",
        "        train_accuracy = 100 * train_correct / train_total\n",
        "\n",
        "        model.eval()\n",
        "        test_loss = 0\n",
        "        test_correct = 0\n",
        "        test_total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in test_dataloader:\n",
        "                inputs, labels = batch\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = loss_fn(outputs, labels)\n",
        "                test_loss += loss.item()\n",
        "\n",
        "                # Précision pour l'ensemble de test\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                test_total += labels.size(0)\n",
        "                test_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        test_loss /= len(test_dataloader)\n",
        "        test_accuracy = 100 * test_correct / test_total\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n",
        "\n",
        "# Entraîner le modèle\n",
        "results = train(model=model,\n",
        "                train_dataloader=train_dataloader,\n",
        "                test_dataloader=test_dataloader,\n",
        "                optimizer=optimizer,\n",
        "                loss_fn=loss_fn,\n",
        "                epochs=10,\n",
        "                device=device)\n",
        "\n",
        "print(results)#best result 95,47\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s06Euk7ASCdW",
        "outputId": "52ca11f6-0004-43fb-dc7d-7ba6007f0079"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Train Loss: 0.2326, Train Accuracy: 90.50%, Test Loss: 0.3952, Test Accuracy: 83.38%\n",
            "Epoch 2/10, Train Loss: 0.1093, Train Accuracy: 95.80%, Test Loss: 0.2531, Test Accuracy: 91.84%\n",
            "Epoch 3/10, Train Loss: 0.0728, Train Accuracy: 97.45%, Test Loss: 0.2729, Test Accuracy: 90.46%\n",
            "Epoch 4/10, Train Loss: 0.0541, Train Accuracy: 98.10%, Test Loss: 0.1456, Test Accuracy: 94.45%\n",
            "Epoch 5/10, Train Loss: 0.0466, Train Accuracy: 98.41%, Test Loss: 0.3512, Test Accuracy: 89.37%\n",
            "Epoch 6/10, Train Loss: 0.0339, Train Accuracy: 98.87%, Test Loss: 0.9188, Test Accuracy: 80.62%\n",
            "Epoch 7/10, Train Loss: 0.0277, Train Accuracy: 99.10%, Test Loss: 0.3625, Test Accuracy: 90.33%\n",
            "Epoch 8/10, Train Loss: 0.0218, Train Accuracy: 99.28%, Test Loss: 0.2507, Test Accuracy: 93.51%\n",
            "Epoch 9/10, Train Loss: 0.0214, Train Accuracy: 99.34%, Test Loss: 0.2685, Test Accuracy: 92.71%\n",
            "Epoch 10/10, Train Loss: 0.0152, Train Accuracy: 99.54%, Test Loss: 0.1783, Test Accuracy: 95.47%\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For efficientnet-b0"
      ],
      "metadata": {
        "id": "7kMpQNYTRUA3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_coefficient(preds, labels, smooth=1e-6):\n",
        "    \"\"\"\n",
        "    Compute the Dice coefficient.\n",
        "\n",
        "    Args:\n",
        "    preds (torch.Tensor): Predictions from the model (logits).\n",
        "    labels (torch.Tensor): Ground truth labels.\n",
        "\n",
        "    Returns:\n",
        "    float: Dice coefficient score.\n",
        "    \"\"\"\n",
        "    # Apply softmax to predictions if necessary and get predicted classes\n",
        "    preds = torch.argmax(torch.softmax(preds, dim=1), dim=1)\n",
        "\n",
        "    # Flatten tensors\n",
        "    preds = preds.contiguous().view(-1)\n",
        "    labels = labels.contiguous().view(-1)\n",
        "\n",
        "    # Compute the intersection\n",
        "    intersection = (preds * labels).sum().float()\n",
        "    # Compute the union\n",
        "    union = preds.sum().float() + labels.sum().float()\n",
        "\n",
        "    dice = (2. * intersection + smooth) / (union + smooth)\n",
        "    return dice.item()\n"
      ],
      "metadata": {
        "id": "I-ShQbs7NmWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_dataloader, test_dataloader, optimizer, loss_fn, epochs, device):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        train_correct = 0\n",
        "        train_total = 0\n",
        "        train_dice = 0  # Initialize train dice score\n",
        "\n",
        "        for batch in train_dataloader:\n",
        "            inputs, labels = batch\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "            # Précision pour l'ensemble d'entraînement\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "\n",
        "            # Dice coefficient for training\n",
        "            train_dice += dice_coefficient(outputs, labels)\n",
        "\n",
        "        train_loss /= len(train_dataloader)\n",
        "        train_accuracy = 100 * train_correct / train_total\n",
        "        train_dice /= len(train_dataloader)  # Average dice score\n",
        "\n",
        "        model.eval()\n",
        "        test_loss = 0\n",
        "        test_correct = 0\n",
        "        test_total = 0\n",
        "        test_dice = 0  # Initialize test dice score\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in test_dataloader:\n",
        "                inputs, labels = batch\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = loss_fn(outputs, labels)\n",
        "                test_loss += loss.item()\n",
        "\n",
        "                # Précision pour l'ensemble de test\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                test_total += labels.size(0)\n",
        "                test_correct += (predicted == labels).sum().item()\n",
        "\n",
        "                # Dice coefficient for testing\n",
        "                test_dice += dice_coefficient(outputs, labels)\n",
        "\n",
        "        test_loss /= len(test_dataloader)\n",
        "        test_accuracy = 100 * test_correct / test_total\n",
        "        test_dice /= len(test_dataloader)  # Average dice score\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "id": "f4MuWYGrNpyG"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = train(model=model,\n",
        "                train_dataloader=train_dataloader,\n",
        "                test_dataloader=test_dataloader,\n",
        "                optimizer=optimizer,\n",
        "                loss_fn=loss_fn,\n",
        "                epochs=10,\n",
        "                device=device)\n",
        "\n",
        "print(results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "G-Idi3l4Nr-P",
        "outputId": "0cbbf328-2a2f-47bf-d86d-0d56cba4d378"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-1d8113bebf18>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m results = train(model=model,\n\u001b[0m\u001b[1;32m      2\u001b[0m                 \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                 \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0mloss_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weight = torchvision.models.EfficientNet_B0_Weights.DEFAULT # .DEFAULT = best available weights\n",
        "model = torchvision.models.efficientnet_b0(weights=weight).to(device)\n",
        "\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# train all params\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "output_shape = len(class_names)\n",
        "\n",
        "\n",
        "model.classifier = torch.nn.Sequential(\n",
        "    torch.nn.Dropout(p=0.2, inplace=True),\n",
        "    torch.nn.Linear(in_features=1280,\n",
        "                    out_features=output_shape,\n",
        "                    bias=True)).to(device)\n",
        "\n",
        "\n",
        "results = train(model=model,\n",
        "                       train_dataloader=train_dataloader,\n",
        "                       test_dataloader=test_dataloader,\n",
        "                       optimizer=optimizer,\n",
        "                       loss_fn=loss_fn,\n",
        "                       epochs=10,\n",
        "                       device=device) # best 94.65%"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLqAPUGqRW1N",
        "outputId": "87cd689f-af4d-4bc7-83ec-5c9896328b00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n",
            "100%|██████████| 20.5M/20.5M [00:00<00:00, 68.3MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Train Loss: 0.1343, Train Accuracy: 94.76%, Test Loss: 0.1970, Test Accuracy: 93.11%\n",
            "Epoch 2/10, Train Loss: 0.0522, Train Accuracy: 98.23%, Test Loss: 0.2132, Test Accuracy: 94.63%\n",
            "Epoch 3/10, Train Loss: 0.0378, Train Accuracy: 98.78%, Test Loss: 0.2174, Test Accuracy: 94.57%\n",
            "Epoch 4/10, Train Loss: 0.0302, Train Accuracy: 98.99%, Test Loss: 0.2174, Test Accuracy: 94.09%\n",
            "Epoch 5/10, Train Loss: 0.0278, Train Accuracy: 99.08%, Test Loss: 0.1951, Test Accuracy: 93.84%\n",
            "Epoch 6/10, Train Loss: 0.0236, Train Accuracy: 99.30%, Test Loss: 0.2179, Test Accuracy: 94.13%\n",
            "Epoch 7/10, Train Loss: 0.0195, Train Accuracy: 99.42%, Test Loss: 0.2101, Test Accuracy: 94.65%\n",
            "Epoch 8/10, Train Loss: 0.0185, Train Accuracy: 99.43%, Test Loss: 0.2273, Test Accuracy: 93.53%\n",
            "Epoch 9/10, Train Loss: 0.0191, Train Accuracy: 99.40%, Test Loss: 0.2832, Test Accuracy: 92.09%\n",
            "Epoch 10/10, Train Loss: 0.0137, Train Accuracy: 99.56%, Test Loss: 0.2688, Test Accuracy: 92.69%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For densenet121"
      ],
      "metadata": {
        "id": "ENBAOxoLR5z8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_coefficient(preds, labels, smooth=1e-6):\n",
        "    \"\"\"\n",
        "    Compute the Dice coefficient.\n",
        "\n",
        "    Args:\n",
        "    preds (torch.Tensor): Predictions from the model (logits).\n",
        "    labels (torch.Tensor): Ground truth labels.\n",
        "\n",
        "    Returns:\n",
        "    float: Dice coefficient score.\n",
        "    \"\"\"\n",
        "    # Apply softmax to predictions if necessary and get predicted classes\n",
        "    preds = torch.argmax(torch.softmax(preds, dim=1), dim=1)\n",
        "\n",
        "    # Flatten tensors\n",
        "    preds = preds.contiguous().view(-1)\n",
        "    labels = labels.contiguous().view(-1)\n",
        "\n",
        "    # Compute the intersection\n",
        "    intersection = (preds * labels).sum().float()\n",
        "    # Compute the union\n",
        "    union = preds.sum().float() + labels.sum().float()\n",
        "\n",
        "    dice = (2. * intersection + smooth) / (union + smooth)\n",
        "    return dice.item()\n"
      ],
      "metadata": {
        "id": "SFfPkG6gQo7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_dataloader, test_dataloader, optimizer, loss_fn, epochs, device):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        train_correct = 0\n",
        "        train_total = 0\n",
        "        train_dice = 0  # Initialize train dice score\n",
        "\n",
        "        for batch in train_dataloader:\n",
        "            inputs, labels = batch\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "            # Précision pour l'ensemble d'entraînement\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "\n",
        "            # Dice coefficient for training\n",
        "            train_dice += dice_coefficient(outputs, labels)\n",
        "\n",
        "        train_loss /= len(train_dataloader)\n",
        "        train_accuracy = 100 * train_correct / train_total\n",
        "        train_dice /= len(train_dataloader)  # Average dice score\n",
        "\n",
        "        model.eval()\n",
        "        test_loss = 0\n",
        "        test_correct = 0\n",
        "        test_total = 0\n",
        "        test_dice = 0  # Initialize test dice score\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in test_dataloader:\n",
        "                inputs, labels = batch\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = loss_fn(outputs, labels)\n",
        "                test_loss += loss.item()\n",
        "\n",
        "                # Précision pour l'ensemble de test\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                test_total += labels.size(0)\n",
        "                test_correct += (predicted == labels).sum().item()\n",
        "\n",
        "                # Dice coefficient for testing\n",
        "                test_dice += dice_coefficient(outputs, labels)\n",
        "\n",
        "        test_loss /= len(test_dataloader)\n",
        "        test_accuracy = 100 * test_correct / test_total\n",
        "        test_dice /= len(test_dataloader)  # Average dice score\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, Train Dice: {train_dice:.4f}, Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%, Test Dice: {test_dice:.4f}\")\n"
      ],
      "metadata": {
        "id": "ChBzcxhMQraN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = train(model=model,\n",
        "                train_dataloader=train_dataloader,\n",
        "                test_dataloader=test_dataloader,\n",
        "                optimizer=optimizer,\n",
        "                loss_fn=loss_fn,\n",
        "                epochs=10,\n",
        "                device=device)\n",
        "\n",
        "print(results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhDszRbsQrvD",
        "outputId": "13d71781-8cc5-47ae-d598-e4a22fd9203c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Train Loss: 0.0109, Train Accuracy: 99.68%, Train Dice: 0.9957, Test Loss: 0.1869, Test Accuracy: 95.72%, Test Dice: 0.6331\n",
            "Epoch 2/10, Train Loss: 0.0051, Train Accuracy: 99.84%, Train Dice: 0.9978, Test Loss: 0.2555, Test Accuracy: 93.26%, Test Dice: 0.6049\n",
            "Epoch 3/10, Train Loss: 0.0046, Train Accuracy: 99.85%, Train Dice: 0.9979, Test Loss: 0.2754, Test Accuracy: 94.22%, Test Dice: 0.5538\n",
            "Epoch 4/10, Train Loss: 0.0068, Train Accuracy: 99.79%, Train Dice: 0.9969, Test Loss: 0.2079, Test Accuracy: 95.43%, Test Dice: 0.6816\n",
            "Epoch 5/10, Train Loss: 0.0032, Train Accuracy: 99.91%, Train Dice: 0.9989, Test Loss: 0.2400, Test Accuracy: 94.11%, Test Dice: 0.5970\n",
            "Epoch 6/10, Train Loss: 0.0067, Train Accuracy: 99.78%, Train Dice: 0.9971, Test Loss: 0.2319, Test Accuracy: 94.97%, Test Dice: 0.6480\n",
            "Epoch 7/10, Train Loss: 0.0037, Train Accuracy: 99.88%, Train Dice: 0.9983, Test Loss: 0.2703, Test Accuracy: 93.13%, Test Dice: 0.6370\n",
            "Epoch 8/10, Train Loss: 0.0063, Train Accuracy: 99.79%, Train Dice: 0.9970, Test Loss: 0.2565, Test Accuracy: 94.15%, Test Dice: 0.5971\n",
            "Epoch 9/10, Train Loss: 0.0012, Train Accuracy: 99.96%, Train Dice: 0.9995, Test Loss: 0.2595, Test Accuracy: 94.74%, Test Dice: 0.6711\n",
            "Epoch 10/10, Train Loss: 0.0075, Train Accuracy: 99.76%, Train Dice: 0.9967, Test Loss: 0.2214, Test Accuracy: 94.76%, Test Dice: 0.5199\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights = torchvision.models.DenseNet121_Weights.DEFAULT\n",
        "model = torchvision.models.densenet121(weights=weights).to(device)\n",
        "\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# train all params\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "output_shape = len(class_names)\n",
        "\n",
        "\n",
        "model.classifier = torch.nn.Sequential(\n",
        "    torch.nn.Dropout(p=0.2, inplace=True),\n",
        "    torch.nn.Linear(in_features=1024,\n",
        "                    out_features=output_shape,\n",
        "                    bias=True)).to(device)\n",
        "\n",
        "\n",
        "results = train(model=model,\n",
        "                       train_dataloader=train_dataloader,\n",
        "                       test_dataloader=test_dataloader,\n",
        "                       optimizer=optimizer,\n",
        "                       loss_fn=loss_fn,\n",
        "                       epochs=10,\n",
        "                       device=device) # best is 93.46"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roWb55mmR8wt",
        "outputId": "b3d744f9-10c4-4c58-9749-4949ed3ef670"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n",
            "100%|██████████| 30.8M/30.8M [00:00<00:00, 180MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Train Loss: 0.2353, Train Accuracy: 89.98%, Test Loss: 0.2632, Test Accuracy: 90.21%\n",
            "Epoch 2/10, Train Loss: 0.1106, Train Accuracy: 95.83%, Test Loss: 0.2275, Test Accuracy: 91.36%\n",
            "Epoch 3/10, Train Loss: 0.0784, Train Accuracy: 97.10%, Test Loss: 0.2459, Test Accuracy: 91.33%\n",
            "Epoch 4/10, Train Loss: 0.0554, Train Accuracy: 98.05%, Test Loss: 0.2322, Test Accuracy: 91.54%\n",
            "Epoch 5/10, Train Loss: 0.0471, Train Accuracy: 98.29%, Test Loss: 0.2209, Test Accuracy: 92.07%\n",
            "Epoch 6/10, Train Loss: 0.0407, Train Accuracy: 98.65%, Test Loss: 0.4539, Test Accuracy: 87.55%\n",
            "Epoch 7/10, Train Loss: 0.0330, Train Accuracy: 98.91%, Test Loss: 0.2483, Test Accuracy: 93.46%\n",
            "Epoch 8/10, Train Loss: 0.0350, Train Accuracy: 98.84%, Test Loss: 0.2114, Test Accuracy: 92.78%\n",
            "Epoch 9/10, Train Loss: 0.0244, Train Accuracy: 99.19%, Test Loss: 0.2361, Test Accuracy: 92.94%\n",
            "Epoch 10/10, Train Loss: 0.0210, Train Accuracy: 99.34%, Test Loss: 0.3440, Test Accuracy: 91.81%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_coef(outputs, labels, smooth=1):\n",
        "    intersection = (outputs * labels).sum()\n",
        "    union = outputs.sum() + labels.sum()\n",
        "    dice = (2. * intersection + smooth) / (union + smooth)\n",
        "    return dice\n",
        "weights = torchvision.models.DenseNet121_Weights.DEFAULT\n",
        "model = torchvision.models.densenet121(weights=weights).to(device)\n",
        "\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# train all params\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "output_shape = len(class_names)\n",
        "\n",
        "\n",
        "model.classifier = torch.nn.Sequential(\n",
        "    torch.nn.Dropout(p=0.2, inplace=True),\n",
        "    torch.nn.Linear(in_features=1024,\n",
        "                    out_features=output_shape,\n",
        "                    bias=True)).to(device)\n",
        "\n",
        "\n",
        "results = train(model=model,\n",
        "                       train_dataloader=train_dataloader,\n",
        "                       test_dataloader=test_dataloader,\n",
        "                       optimizer=optimizer,\n",
        "                       loss_fn=loss_fn,\n",
        "                       epochs=10,\n",
        "                       device=device) # best is 93.46"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAQemIu9VTyc",
        "outputId": "d67371a9-f7e4-41a2-9720-fc71c085ce4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n",
            "100%|██████████| 30.8M/30.8M [00:00<00:00, 127MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Train Loss: 0.2386, Train Accuracy: 89.94%, Train Dice: 0.8623, Test Loss: 0.3391, Test Accuracy: 85.34%, Test Dice: 0.3593\n",
            "Epoch 2/10, Train Loss: 0.1180, Train Accuracy: 95.53%, Train Dice: 0.9385, Test Loss: 0.6262, Test Accuracy: 83.80%, Test Dice: 0.3849\n",
            "Epoch 3/10, Train Loss: 0.0815, Train Accuracy: 97.08%, Train Dice: 0.9601, Test Loss: 0.2350, Test Accuracy: 91.50%, Test Dice: 0.6268\n",
            "Epoch 4/10, Train Loss: 0.0595, Train Accuracy: 97.91%, Train Dice: 0.9713, Test Loss: 0.3136, Test Accuracy: 88.81%, Test Dice: 0.6172\n",
            "Epoch 5/10, Train Loss: 0.0499, Train Accuracy: 98.37%, Train Dice: 0.9778, Test Loss: 0.1873, Test Accuracy: 93.26%, Test Dice: 0.6127\n",
            "Epoch 6/10, Train Loss: 0.0439, Train Accuracy: 98.45%, Train Dice: 0.9789, Test Loss: 0.2364, Test Accuracy: 91.77%, Test Dice: 0.5087\n",
            "Epoch 7/10, Train Loss: 0.0375, Train Accuracy: 98.77%, Train Dice: 0.9829, Test Loss: 0.2516, Test Accuracy: 91.65%, Test Dice: 0.5331\n"
          ]
        }
      ]
    }
  ]
}